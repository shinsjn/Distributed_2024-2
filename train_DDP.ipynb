{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64447c74",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.101155Z",
     "start_time": "2024-11-04T06:04:45.095487Z"
    }
   },
   "cell_type": "code",
   "source": "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia",
   "id": "f895e3e19041882c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "34dc5bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.158246Z",
     "start_time": "2024-11-04T06:04:45.148115Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import datetime\n",
    "\n",
    "from dataloader import *\n",
    "\n",
    "from model_distribution import *"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "3038d51f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "id": "feb3d5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.199774Z",
     "start_time": "2024-11-04T06:04:45.196301Z"
    }
   },
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "conv1d_dim1 = 32\n",
    "conv1d_dim2 = 64\n",
    "conv1d_dim3 = 128\n",
    "dense_dim = 256\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epochs = 2000\n",
    "\n",
    "criterion_distribution = nn.GaussianNLLLoss()"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "0e5d0ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.257360Z",
     "start_time": "2024-11-04T06:04:45.246596Z"
    }
   },
   "source": [
    "# 경로 입력 및 아이디 추출\n",
    "\n",
    "file_path = \"./data/total/\"\n",
    "data_path = glob.glob(file_path + '*')\n",
    "name = []\n",
    "for file_name in data_path:\n",
    "    folder_name = os.path.split(file_name)[1][:7]\n",
    "    name += [folder_name]\n",
    "    \n",
    "id_name = np.unique(name)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "190fe5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.292411Z",
     "start_time": "2024-11-04T06:04:45.288428Z"
    }
   },
   "source": [
    "id_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IF00017', 'IF00024', 'IF00034', 'IF00041', 'IF01020', 'IF01045',\n",
       "       'IF01047', 'IF02035', 'IF03014', 'IF03027', 'IF03039', 'IF94031',\n",
       "       'IF99008', 'IF99013', 'IF99030', 'IF99032', 'IM01006', 'IM01029',\n",
       "       'IM02040', 'IM03011', 'IM03048', 'IM96018', 'IM96033', 'IM97015',\n",
       "       'IM98009', 'IM98019', 'IM98026', 'IM98036', 'IM98042', 'IM98049',\n",
       "       'IM98050', 'IM99007', 'IM99010', 'IM99012', 'IM99021', 'IM99025',\n",
       "       'IM99037'], dtype='<U7')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "a893c2be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.348471Z",
     "start_time": "2024-11-04T06:04:45.343349Z"
    }
   },
   "source": [
    "test_id = np.array(['IF03014', 'IF00041', 'IM02040', 'IM98049'])\n",
    "# test_id = np.array(['IF03014', 'IF00041', 'IM02040', 'IM98042'])"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "71aaea7b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:46.802144Z",
     "start_time": "2024-11-04T06:04:45.386954Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "\n",
    "# seed 고정\n",
    "random_seed = 77\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "def train_ddp(rank, world_size):\n",
    "    # 분산 학습 초기화\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "    # 데이터셋 준비 및 K-Fold\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=random_seed)\n",
    "    id_name_trnval = np.setdiff1d(id_name, test_id)\n",
    "    best_MAE_fold = 0\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(id_name_trnval)):\n",
    "        train_id = id_name_trnval[train_idx]\n",
    "        valid_id = id_name_trnval[valid_idx]\n",
    "\n",
    "        print('Train ID : {}\\n Valid ID {}'.format(train_id, valid_id))\n",
    "        \n",
    "        train_dataset_R = Gait_Dataset_Salted(file_path, train_id, right=True)\n",
    "        train_dataset_L = Gait_Dataset_Salted(file_path, train_id, right=False)\n",
    "        valid_dataset_R = Gait_Dataset_Salted(file_path, valid_id, right=True)\n",
    "        valid_dataset_L = Gait_Dataset_Salted(file_path, valid_id, right=False)\n",
    "\n",
    "        train_dataset = torch.utils.data.ConcatDataset([train_dataset_R, train_dataset_L])\n",
    "        valid_dataset = torch.utils.data.ConcatDataset([valid_dataset_R, valid_dataset_L])\n",
    "\n",
    "        # DistributedSampler로 데이터 로더 생성\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, sampler=train_sampler)\n",
    "        val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, sampler=valid_sampler)\n",
    "\n",
    "        print('Fold {} Dataloader Load Complete'.format(fold+1))\n",
    "\n",
    "        # 모델 정의 및 DDP로 감싸기\n",
    "        model = Encoder(conv1d_dim1, conv1d_dim2, conv1d_dim3, dense_dim).to(rank)\n",
    "        model = DDP(model, device_ids=[rank])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Early Stopping을 위한 변수\n",
    "        best = 10000\n",
    "        converge_cnt = 0\n",
    "        best_MAE = 1000\n",
    "        best_epoch = 0\n",
    "\n",
    "        # 학습 시작 시간 기록\n",
    "        start_time = datetime.datetime.now()\n",
    "        print(f\"Training started at: {start_time}\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            tot_trn_loss = 0.0\n",
    "\n",
    "            model.train()\n",
    "            train_sampler.set_epoch(epoch)  # Shuffle each epoch\n",
    "\n",
    "            for i, data in enumerate(train_loader):\n",
    "                inputs_acc, inputs_gyr, inputs_prs, stride_length, mu, sigma, folder_id = data\n",
    "                inputs_acc, inputs_gyr, inputs_prs, stride_length, mu, sigma = inputs_acc.float(), inputs_gyr.float(), inputs_prs.float(), stride_length.float(), mu.float(), sigma.float()\n",
    "                inputs_acc, inputs_gyr, inputs_prs = inputs_acc.to(rank), inputs_gyr.to(rank), inputs_prs.to(rank)\n",
    "                mu, sigma = mu.reshape(-1, 1).to(rank), sigma.reshape(-1, 1).to(rank)\n",
    "                stride_length = stride_length.reshape(-1, 1).to(rank)\n",
    "\n",
    "                outputs, var = model(inputs_acc, inputs_gyr, inputs_prs)\n",
    "                loss = criterion_distribution(mu, outputs, var)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tot_trn_loss += loss.item()\n",
    "\n",
    "            # Evaluation Mode\n",
    "            model.eval()\n",
    "            tot_val_loss = 0\n",
    "            tot_val_MAE = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    inputs_acc, inputs_gyr, inputs_prs, stride_length, mu, sigma, folder_id = data\n",
    "                    inputs_acc, inputs_gyr, inputs_prs, stride_length, mu, sigma = inputs_acc.float(), inputs_gyr.float(), inputs_prs.float(), stride_length.float(), mu.float(), sigma.float()\n",
    "                    inputs_acc, inputs_gyr, inputs_prs = inputs_acc.to(rank), inputs_gyr.to(rank), inputs_prs.to(rank)\n",
    "                    mu, sigma = mu.reshape(-1, 1).to(rank), sigma.reshape(-1, 1).to(rank)\n",
    "                    stride_length = stride_length.reshape(-1, 1).to(rank)\n",
    "\n",
    "                    outputs, var = model(inputs_acc, inputs_gyr, inputs_prs)\n",
    "                    loss = criterion_distribution(mu, outputs, var)\n",
    "                    tot_val_loss += loss.item()\n",
    "                    tot_val_MAE += torch.sum(torch.abs(outputs - stride_length)) / len(stride_length)\n",
    "\n",
    "            trn_loss = tot_trn_loss / len(train_loader)\n",
    "            val_loss = tot_val_loss / len(val_loader)\n",
    "            MAE = tot_val_MAE / len(val_loader)\n",
    "\n",
    "            # Early Stopping\n",
    "            if val_loss < best:\n",
    "                best = np.mean(val_loss)\n",
    "                best_MAE = MAE\n",
    "                best_epoch = epoch+1\n",
    "                if rank == 0:  # Only save model from rank 0 process\n",
    "                    torch.save(deepcopy(model.state_dict()), f'./model/L2/L2_fold{fold+1}.pth')\n",
    "                converge_cnt = 0\n",
    "            else:\n",
    "                converge_cnt += 1\n",
    "\n",
    "            if converge_cnt > 50:\n",
    "                print(f'Early stopping: Fold {fold+1}, Epoch {best_epoch}, Valid Loss {best:.3f}, MAE {best_MAE:.3f}')\n",
    "                best_MAE_fold += best_MAE\n",
    "                break\n",
    "\n",
    "        # 학습 종료 시간 및 경과 시간 계산\n",
    "        end_time = datetime.datetime.now()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Training ended at: {end_time}\")\n",
    "        print(f\"Total training time: {elapsed_time}\")\n",
    "\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train_ddp, args=(world_size,), nprocs=world_size)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shinsjn/miniconda3/envs/Jupyter_test/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shinsjn/miniconda3/envs/Jupyter_test/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_ddp' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shinsjn/miniconda3/envs/Jupyter_test/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shinsjn/miniconda3/envs/Jupyter_test/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_ddp' on <module '__main__' (built-in)>\n",
      "W1104 15:04:46.750000 140126867067520 torch/multiprocessing/spawn.py:146] Terminating process 25742 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mProcessExitedException\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 143\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    142\u001B[0m     world_size \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[0;32m--> 143\u001B[0m     \u001B[43mmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ddp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Jupyter_test/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:282\u001B[0m, in \u001B[0;36mspawn\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    276\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis method only supports start_method=spawn (got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_method\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use a different start_method use:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m torch.multiprocessing.start_processes(...)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m     )\n\u001B[1;32m    281\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdaemon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspawn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Jupyter_test/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:238\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m context\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 238\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Jupyter_test/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:178\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    171\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with signal \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, name),\n\u001B[1;32m    172\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    175\u001B[0m             signal_name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m    176\u001B[0m         )\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    179\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with exit code \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, exitcode),\n\u001B[1;32m    180\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[1;32m    181\u001B[0m             error_pid\u001B[38;5;241m=\u001B[39mfailed_process\u001B[38;5;241m.\u001B[39mpid,\n\u001B[1;32m    182\u001B[0m             exit_code\u001B[38;5;241m=\u001B[39mexitcode,\n\u001B[1;32m    183\u001B[0m         )\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_files[error_index], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fh:\n\u001B[1;32m    186\u001B[0m     original_trace \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(fh)\n",
      "\u001B[0;31mProcessExitedException\u001B[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "601ff15e",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d260465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.630050700Z",
     "start_time": "2024-11-04T06:01:43.559945Z"
    }
   },
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "test_file_path = \"./data/total/\"\n",
    "\n",
    "test_dataset_R = Gait_Dataset_Salted(test_file_path, test_id, right=True)\n",
    "test_dataset_L = Gait_Dataset_Salted(test_file_path, test_id, right=False)\n",
    "\n",
    "test_dataset = torch.utils.data.ConcatDataset([test_dataset_R, test_dataset_L])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                       batch_size=256,\n",
    "                                       shuffle=False,\n",
    "                                       worker_init_fn=np.random.seed(42))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "b896ff8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T06:04:45.630050700Z",
     "start_time": "2024-11-04T06:01:44.655654Z"
    }
   },
   "source": [
    "### Scatter Plot \n",
    "\n",
    "conv1d_dim1 = 32\n",
    "conv1d_dim2 = 64\n",
    "conv1d_dim3 = 128\n",
    "dense_dim = 256\n",
    "\n",
    "stride_length_list = pd.DataFrame()\n",
    "sigma_list = pd.DataFrame()\n",
    "tot_val_MAE = 0\n",
    "tot_val_MAPE = 0\n",
    "\n",
    "for fold_idx, model_name in enumerate(glob.glob('./model/L2/L2_fold' + '*')):\n",
    "    print(model_name)\n",
    "    model = Encoder(conv1d_dim1, conv1d_dim2, conv1d_dim3, dense_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs_acc, inputs_gyr, inputs_prs, stride_length, mu, sigma, folder_id = data\n",
    "        inputs_acc, inputs_gyr, inputs_prs, stride_length = inputs_acc.float(), inputs_gyr.float(), inputs_prs.float(), stride_length.float() \n",
    "        inputs_acc, inputs_gyr, inputs_prs = inputs_acc.to(device), inputs_gyr.to(device), inputs_prs.to(device)\n",
    "\n",
    "        stride_length = stride_length.reshape(-1, 1)\n",
    "        stride_length = stride_length.to(device)\n",
    "\n",
    "        outputs = model(inputs_acc, inputs_gyr, inputs_prs)\n",
    "        stride_length_list.loc[:, fold_idx] = outputs[0].reshape(-1).cpu().detach().numpy()\n",
    "        sigma_list.loc[:, fold_idx] = outputs[1].reshape(-1).cpu().detach().numpy()\n",
    "        \n",
    "pred = stride_length_list.mean(axis=1)\n",
    "stride_length = stride_length.reshape(-1).cpu().detach().numpy()\n",
    "# stride_length = stride_length.reshape(-1)\n",
    "\n",
    "mu = mu.cpu().detach().numpy()\n",
    "# mu = mu\n",
    "\n",
    "# print(pred)\n",
    "# print(stride_length_list)\n",
    "MAE = np.sum(np.abs(pred - stride_length)) / len(stride_length)\n",
    "MAPE = 100 - (np.mean(np.abs(pred - stride_length) / stride_length) * 100)\n",
    "RMSE = np.sqrt(np.mean((stride_length - pred)**2))\n",
    "RSE = RMSE / np.sqrt(np.sum((stride_length - mu)**2))\n",
    "\n",
    "\n",
    "print('MAE : {:.4f}, MAPE : {:.2f}%, RMSE : {:.4f}, RSE : {:.4f}'.format(MAE, MAPE, RMSE, RSE))\n",
    "# print('MAE : {:.4f}'.format(MAE))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(stride_length, pred)\n",
    "plt.xlim([80, 200])\n",
    "plt.xlabel('stride_length')\n",
    "plt.ylim([80, 200])\n",
    "plt.ylabel('pred')\n",
    "\n",
    "xpoints = ypoints = plt.xlim()\n",
    "plt.plot(xpoints, ypoints, linestyle='--', color='k', lw=3, scalex=False, scaley=False)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/L2/L2_fold8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24848/1117567588.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/L2/L2_fold7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24848/1117567588.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/L2/L2_fold9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24848/1117567588.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/L2/L2_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24848/1117567588.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/L2/L2_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24848/1117567588.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Encoder:\n\tMissing key(s) in state_dict: \"conv1d_acc.0.weight\", \"conv1d_acc.0.bias\", \"conv1d_acc.1.weight\", \"conv1d_acc.1.bias\", \"conv1d_acc.1.running_mean\", \"conv1d_acc.1.running_var\", \"conv1d_acc.3.weight\", \"conv1d_acc.3.bias\", \"conv1d_acc.4.weight\", \"conv1d_acc.4.bias\", \"conv1d_acc.4.running_mean\", \"conv1d_acc.4.running_var\", \"conv1d_acc.6.weight\", \"conv1d_acc.6.bias\", \"conv1d_acc.7.weight\", \"conv1d_acc.7.bias\", \"conv1d_acc.7.running_mean\", \"conv1d_acc.7.running_var\", \"conv1d_gyr.0.weight\", \"conv1d_gyr.0.bias\", \"conv1d_gyr.1.weight\", \"conv1d_gyr.1.bias\", \"conv1d_gyr.1.running_mean\", \"conv1d_gyr.1.running_var\", \"conv1d_gyr.3.weight\", \"conv1d_gyr.3.bias\", \"conv1d_gyr.4.weight\", \"conv1d_gyr.4.bias\", \"conv1d_gyr.4.running_mean\", \"conv1d_gyr.4.running_var\", \"conv1d_gyr.6.weight\", \"conv1d_gyr.6.bias\", \"conv1d_gyr.7.weight\", \"conv1d_gyr.7.bias\", \"conv1d_gyr.7.running_mean\", \"conv1d_gyr.7.running_var\", \"conv1d_prs.0.weight\", \"conv1d_prs.0.bias\", \"conv1d_prs.1.weight\", \"conv1d_prs.1.bias\", \"conv1d_prs.1.running_mean\", \"conv1d_prs.1.running_var\", \"conv1d_prs.3.weight\", \"conv1d_prs.3.bias\", \"conv1d_prs.4.weight\", \"conv1d_prs.4.bias\", \"conv1d_prs.4.running_mean\", \"conv1d_prs.4.running_var\", \"conv1d_prs.6.weight\", \"conv1d_prs.6.bias\", \"conv1d_prs.7.weight\", \"conv1d_prs.7.bias\", \"conv1d_prs.7.running_mean\", \"conv1d_prs.7.running_var\", \"dense_mean.0.weight\", \"dense_mean.0.bias\", \"dense_mean.2.weight\", \"dense_mean.2.bias\", \"dense_mean.4.weight\", \"dense_mean.4.bias\", \"dense_var.0.weight\", \"dense_var.0.bias\", \"dense_var.2.weight\", \"dense_var.2.bias\", \"dense_var.4.weight\", \"dense_var.4.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1d_acc.0.weight\", \"module.conv1d_acc.0.bias\", \"module.conv1d_acc.1.weight\", \"module.conv1d_acc.1.bias\", \"module.conv1d_acc.1.running_mean\", \"module.conv1d_acc.1.running_var\", \"module.conv1d_acc.1.num_batches_tracked\", \"module.conv1d_acc.3.weight\", \"module.conv1d_acc.3.bias\", \"module.conv1d_acc.4.weight\", \"module.conv1d_acc.4.bias\", \"module.conv1d_acc.4.running_mean\", \"module.conv1d_acc.4.running_var\", \"module.conv1d_acc.4.num_batches_tracked\", \"module.conv1d_acc.6.weight\", \"module.conv1d_acc.6.bias\", \"module.conv1d_acc.7.weight\", \"module.conv1d_acc.7.bias\", \"module.conv1d_acc.7.running_mean\", \"module.conv1d_acc.7.running_var\", \"module.conv1d_acc.7.num_batches_tracked\", \"module.conv1d_gyr.0.weight\", \"module.conv1d_gyr.0.bias\", \"module.conv1d_gyr.1.weight\", \"module.conv1d_gyr.1.bias\", \"module.conv1d_gyr.1.running_mean\", \"module.conv1d_gyr.1.running_var\", \"module.conv1d_gyr.1.num_batches_tracked\", \"module.conv1d_gyr.3.weight\", \"module.conv1d_gyr.3.bias\", \"module.conv1d_gyr.4.weight\", \"module.conv1d_gyr.4.bias\", \"module.conv1d_gyr.4.running_mean\", \"module.conv1d_gyr.4.running_var\", \"module.conv1d_gyr.4.num_batches_tracked\", \"module.conv1d_gyr.6.weight\", \"module.conv1d_gyr.6.bias\", \"module.conv1d_gyr.7.weight\", \"module.conv1d_gyr.7.bias\", \"module.conv1d_gyr.7.running_mean\", \"module.conv1d_gyr.7.running_var\", \"module.conv1d_gyr.7.num_batches_tracked\", \"module.conv1d_prs.0.weight\", \"module.conv1d_prs.0.bias\", \"module.conv1d_prs.1.weight\", \"module.conv1d_prs.1.bias\", \"module.conv1d_prs.1.running_mean\", \"module.conv1d_prs.1.running_var\", \"module.conv1d_prs.1.num_batches_tracked\", \"module.conv1d_prs.3.weight\", \"module.conv1d_prs.3.bias\", \"module.conv1d_prs.4.weight\", \"module.conv1d_prs.4.bias\", \"module.conv1d_prs.4.running_mean\", \"module.conv1d_prs.4.running_var\", \"module.conv1d_prs.4.num_batches_tracked\", \"module.conv1d_prs.6.weight\", \"module.conv1d_prs.6.bias\", \"module.conv1d_prs.7.weight\", \"module.conv1d_prs.7.bias\", \"module.conv1d_prs.7.running_mean\", \"module.conv1d_prs.7.running_var\", \"module.conv1d_prs.7.num_batches_tracked\", \"module.dense_mean.0.weight\", \"module.dense_mean.0.bias\", \"module.dense_mean.2.weight\", \"module.dense_mean.2.bias\", \"module.dense_mean.4.weight\", \"module.dense_mean.4.bias\", \"module.dense_var.0.weight\", \"module.dense_var.0.bias\", \"module.dense_var.2.weight\", \"module.dense_var.2.bias\", \"module.dense_var.4.weight\", \"module.dense_var.4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(model_name)\n\u001B[1;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m Encoder(conv1d_dim1, conv1d_dim2, conv1d_dim3, dense_dim)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     18\u001B[0m pred_list \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/miniconda3/envs/Jupyter_test/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[1;32m   2210\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2211\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2212\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[1;32m   2214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2215\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2216\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[1;32m   2217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Encoder:\n\tMissing key(s) in state_dict: \"conv1d_acc.0.weight\", \"conv1d_acc.0.bias\", \"conv1d_acc.1.weight\", \"conv1d_acc.1.bias\", \"conv1d_acc.1.running_mean\", \"conv1d_acc.1.running_var\", \"conv1d_acc.3.weight\", \"conv1d_acc.3.bias\", \"conv1d_acc.4.weight\", \"conv1d_acc.4.bias\", \"conv1d_acc.4.running_mean\", \"conv1d_acc.4.running_var\", \"conv1d_acc.6.weight\", \"conv1d_acc.6.bias\", \"conv1d_acc.7.weight\", \"conv1d_acc.7.bias\", \"conv1d_acc.7.running_mean\", \"conv1d_acc.7.running_var\", \"conv1d_gyr.0.weight\", \"conv1d_gyr.0.bias\", \"conv1d_gyr.1.weight\", \"conv1d_gyr.1.bias\", \"conv1d_gyr.1.running_mean\", \"conv1d_gyr.1.running_var\", \"conv1d_gyr.3.weight\", \"conv1d_gyr.3.bias\", \"conv1d_gyr.4.weight\", \"conv1d_gyr.4.bias\", \"conv1d_gyr.4.running_mean\", \"conv1d_gyr.4.running_var\", \"conv1d_gyr.6.weight\", \"conv1d_gyr.6.bias\", \"conv1d_gyr.7.weight\", \"conv1d_gyr.7.bias\", \"conv1d_gyr.7.running_mean\", \"conv1d_gyr.7.running_var\", \"conv1d_prs.0.weight\", \"conv1d_prs.0.bias\", \"conv1d_prs.1.weight\", \"conv1d_prs.1.bias\", \"conv1d_prs.1.running_mean\", \"conv1d_prs.1.running_var\", \"conv1d_prs.3.weight\", \"conv1d_prs.3.bias\", \"conv1d_prs.4.weight\", \"conv1d_prs.4.bias\", \"conv1d_prs.4.running_mean\", \"conv1d_prs.4.running_var\", \"conv1d_prs.6.weight\", \"conv1d_prs.6.bias\", \"conv1d_prs.7.weight\", \"conv1d_prs.7.bias\", \"conv1d_prs.7.running_mean\", \"conv1d_prs.7.running_var\", \"dense_mean.0.weight\", \"dense_mean.0.bias\", \"dense_mean.2.weight\", \"dense_mean.2.bias\", \"dense_mean.4.weight\", \"dense_mean.4.bias\", \"dense_var.0.weight\", \"dense_var.0.bias\", \"dense_var.2.weight\", \"dense_var.2.bias\", \"dense_var.4.weight\", \"dense_var.4.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1d_acc.0.weight\", \"module.conv1d_acc.0.bias\", \"module.conv1d_acc.1.weight\", \"module.conv1d_acc.1.bias\", \"module.conv1d_acc.1.running_mean\", \"module.conv1d_acc.1.running_var\", \"module.conv1d_acc.1.num_batches_tracked\", \"module.conv1d_acc.3.weight\", \"module.conv1d_acc.3.bias\", \"module.conv1d_acc.4.weight\", \"module.conv1d_acc.4.bias\", \"module.conv1d_acc.4.running_mean\", \"module.conv1d_acc.4.running_var\", \"module.conv1d_acc.4.num_batches_tracked\", \"module.conv1d_acc.6.weight\", \"module.conv1d_acc.6.bias\", \"module.conv1d_acc.7.weight\", \"module.conv1d_acc.7.bias\", \"module.conv1d_acc.7.running_mean\", \"module.conv1d_acc.7.running_var\", \"module.conv1d_acc.7.num_batches_tracked\", \"module.conv1d_gyr.0.weight\", \"module.conv1d_gyr.0.bias\", \"module.conv1d_gyr.1.weight\", \"module.conv1d_gyr.1.bias\", \"module.conv1d_gyr.1.running_mean\", \"module.conv1d_gyr.1.running_var\", \"module.conv1d_gyr.1.num_batches_tracked\", \"module.conv1d_gyr.3.weight\", \"module.conv1d_gyr.3.bias\", \"module.conv1d_gyr.4.weight\", \"module.conv1d_gyr.4.bias\", \"module.conv1d_gyr.4.running_mean\", \"module.conv1d_gyr.4.running_var\", \"module.conv1d_gyr.4.num_batches_tracked\", \"module.conv1d_gyr.6.weight\", \"module.conv1d_gyr.6.bias\", \"module.conv1d_gyr.7.weight\", \"module.conv1d_gyr.7.bias\", \"module.conv1d_gyr.7.running_mean\", \"module.conv1d_gyr.7.running_var\", \"module.conv1d_gyr.7.num_batches_tracked\", \"module.conv1d_prs.0.weight\", \"module.conv1d_prs.0.bias\", \"module.conv1d_prs.1.weight\", \"module.conv1d_prs.1.bias\", \"module.conv1d_prs.1.running_mean\", \"module.conv1d_prs.1.running_var\", \"module.conv1d_prs.1.num_batches_tracked\", \"module.conv1d_prs.3.weight\", \"module.conv1d_prs.3.bias\", \"module.conv1d_prs.4.weight\", \"module.conv1d_prs.4.bias\", \"module.conv1d_prs.4.running_mean\", \"module.conv1d_prs.4.running_var\", \"module.conv1d_prs.4.num_batches_tracked\", \"module.conv1d_prs.6.weight\", \"module.conv1d_prs.6.bias\", \"module.conv1d_prs.7.weight\", \"module.conv1d_prs.7.bias\", \"module.conv1d_prs.7.running_mean\", \"module.conv1d_prs.7.running_var\", \"module.conv1d_prs.7.num_batches_tracked\", \"module.dense_mean.0.weight\", \"module.dense_mean.0.bias\", \"module.dense_mean.2.weight\", \"module.dense_mean.2.bias\", \"module.dense_mean.4.weight\", \"module.dense_mean.4.bias\", \"module.dense_var.0.weight\", \"module.dense_var.0.bias\", \"module.dense_var.2.weight\", \"module.dense_var.2.bias\", \"module.dense_var.4.weight\", \"module.dense_var.4.bias\". "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
